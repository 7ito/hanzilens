# ReadAssist/ReadOverview

### Immediate
- [ ] Input validation (frontend and backend)

### Future
- [ ] Figure out how to do transition

### Features
- [ ] Click on segment to either link to mdbg link or show pop up with all definitions
- [ ] Input next sentence

### Future/Experiment
Functionality works great with current set up to DeepSeek API (deepseek-chat/DeepSeek V3)
However, very slow, already on shorter sentences, especially noticeable (borderline unbearable) on longer sentences
Experiment with letting the LLM give each segment a definition instead of providing CC-CEDICT definitions in prompt (reduce token size)
Can even try allowing it to do everything: segment and definition giving

Function calling?

Train specialized model using BERT

### Before Deployment
- [ ] Input validation (frontend/backend)
- [ ] Introduction page/pop up
- [ ] Stylize buttons/polish UI
- [ ] Daily rate limit
- [ ] Click on component for dictionary lookup

